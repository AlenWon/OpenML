package org.openml.tools.dataset;

import java.io.File;
import java.io.FileReader;

import moa.DoTask;

import org.apache.commons.lang3.StringUtils;
import org.openml.apiconnector.algorithms.Conversion;
import org.openml.apiconnector.io.ApiConnector;
import org.openml.apiconnector.io.ApiSessionHash;
import org.openml.apiconnector.settings.Constants;
import org.openml.apiconnector.xml.DataSetDescription;
import org.openml.apiconnector.xml.UploadDataSet;
import org.openml.apiconnector.xstream.XstreamXmlMapping;

import weka.core.Instances;

import com.thoughtworks.xstream.XStream;

public class GenerateBayesnetDatasets {
	
	private static final String TO = "http://localhost/";
	private static final XStream xstream = XstreamXmlMapping.getInstance();
	private static final ApiSessionHash ash = new ApiSessionHash();
	
	private static final File outputDirectory = new File( "/Users/jan/Desktop/BayesNetTest/" );
	
	private static final String[] searchStrings = {
			"weka.classifiers.bayes.net.search.local.K2 -P 100000 -S BAYES",
//			"weka.classifiers.bayes.net.search.local.GeneticSearch -L 10 -A 20 -U 10 -R 1 -M -C -S BAYES",
//			"weka.classifiers.bayes.net.search.local.SimulatedAnnealing -A 10.0 -U 10000 -D 0.999 -R 1 -S BAYES"
		};
	
	public static void main( String[] args ) throws Exception {
		ApiConnector.API_URL = TO;
		
		ash.set("janvanrijn@gmail.com", "Feyenoord2002");
		
		new GenerateBayesnetDatasets();
	}
	
	public GenerateBayesnetDatasets() throws Exception {
		
		for( int i = 4; i <= 62; ++i ) {
			Conversion.log("INFO", "Download Dataset", "Downloading dataset " + i);
			DataSetDescription dsd = ApiConnector.openmlDataDescription( i );
			
			Instances dataset = new Instances( new FileReader( dsd.getDataset() ) );
			if( dataset.numAttributes() < 20 ) {
				Conversion.log("INFO", "Dataset evaluation", "Dataset " + i + " " + dsd.getName() + " not used. Only " + dataset.numAttributes() + " attributes. " );
				continue;
			} 
			
			for( int j = 0; j < searchStrings.length; ++j ) {
				String datasetname = dsd.getName() + "_" + j + "_" + searchAlgorithmToString( searchStrings[j] );
				String outputFilename = outputDirectory.getAbsolutePath() + "/" + datasetname;
				
				String[] taskArgs = new String[7];
				taskArgs[0] = "WriteStreamToARFFFile";
				taskArgs[1] = "-f";
				taskArgs[2] = outputFilename;
				taskArgs[3] = "-m";
				taskArgs[4] = "50000";
				taskArgs[5] = "-s";
				taskArgs[6] = "(generators.BayesianNetworkGenerator -f (" + dsd.getDataset().getAbsolutePath() + ") -a (" + searchStrings[j] + "))";
				
				Conversion.log("INFO", "Build dataset", "CMD: " + StringUtils.join( taskArgs, ' ' ) );
				DoTask.main( taskArgs );
				Conversion.log("INFO", "Build dataset", "DONE" );
				
				DataSetDescription outputDatasetDescription = new DataSetDescription( datasetname, "Generated by Bayesian Network generation using command " + StringUtils.join( taskArgs, ' ' ), dsd.getFormat(), dsd.getDefault_target_attribute() );
				String outputDatasetString = xstream.toXML( outputDatasetDescription );
				File generatedDataset = new File( outputFilename );
				
				File outputDataset = Conversion.stringToTempFile( outputDatasetString, datasetname, Constants.DATASET_FORMAT );
				
				
				UploadDataSet ud = ApiConnector.openmlDataUpload( outputDataset, generatedDataset, ash.getSessionHash() );
				
				System.out.println( xstream.toXML( ApiConnector.openmlDataDescription( ud.getId() ) ) );
			}
			
			Conversion.log("INFO", "Generating Dataset", "Generating dataset ");
		}
		
	}
	
	private String searchAlgorithmToString( String searchAlgorithmToString ) {
		String[] parts = searchAlgorithmToString.split(" ");
		System.err.println("Parts: " + parts[0]);
		return parts[0].substring( parts[0].lastIndexOf('.') + 1 );
	}
}
